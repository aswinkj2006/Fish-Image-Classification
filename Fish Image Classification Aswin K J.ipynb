{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncDsAP0Gaoa"
   },
   "source": [
    "# **Project Name**    -\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRrZCGUAJYm"
   },
   "source": [
    "##### **Project Type**    - Classification\n",
    "##### **Contribution**    - Individual\n",
    "##### **Team Member 1 - Aswin K J**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJNUwmbgGyua"
   },
   "source": [
    "# **Project Summary -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6v_1wHtG2nS"
   },
   "source": [
    "The project is a comprehensive exploration into building an effective deep learning model for fish image classification, with the end goal of deploying it into a user-friendly web application. The core task was to accurately identify 11 different species of fish from a provided image dataset. The project began with a crucial data preparation phase, where the images were systematically organized into training, validation, and test sets. To ensure the model's robustness and prevent overfitting a common issue where a model memorizes training data instead of learning general features—a technique called data augmentation was applied. This involved creating modified versions of the training images by randomly rotating, flipping, shifting, and zooming them, thereby artificially expanding the dataset and teaching the model to recognize fish from various angles and positions. Five distinct models were then built and rigorously tested to determine the most suitable architecture for this task. The first was a custom Convolutional Neural Network (CNN) created from scratch. The other four leveraged a powerful technique known as transfer learning, where pre-trained models that have already learned to recognize features from millions of images on the ImageNet dataset are adapted for a new task. The architectures chosen for this approach were VGG16, ResNet50, MobileNetV2, and EfficientNetB0. For these models, the pre-trained base layers were kept frozen, and a new custom classifier head was added and trained specifically on the fish images, making the training process highly efficient. After training each model for 10 epochs, a detailed evaluation was conducted on the unseen test data. The results were compiled and compared based on several key metrics, including accuracy, loss, precision, recall, and F1-score. MobileNetV2 emerged as the undisputed winner, achieving a remarkable test accuracy of 99.34%, making it exceptionally reliable for this classification problem. VGG16 and the custom CNN also showed strong results with 93.32% and 89.74% test accuracy, respectively, while ResNet50 and EfficientNetB0 were less effective in this specific setup. With MobileNetV2 identified as the top performer, the project concluded with the deployment phase. The best model was saved as a best_model.h5 file, and the corresponding class names were saved in a class_names.pkl file. Then during deployment since model couldn't be uploaded directly due to problems in the way the model was saved, hence the weights was taken and the model was loaded seperately in the app.py file and the Fish Image Classification project was successfully deployed in Streamlit Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6K7xa23Elo4"
   },
   "source": [
    "# **GitHub Link -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1o69JH3Eqqn"
   },
   "source": [
    "https://github.com/aswinkj2006/Fish-Image-Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaldy8SH6Dl"
   },
   "source": [
    "# **Problem Statement**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpeJGUA3kjGy"
   },
   "source": [
    "This project focuses on classifying fish images into multiple categories using deep learning models. The task involves training a CNN from scratch and leveraging transfer learning with pre-trained models to enhance performance. The project also includes saving models for later use and deploying a Streamlit application to predict fish categories from user-uploaded images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDgbUHAGgjLW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **General Guidelines** : -  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxVaUj-hHfC"
   },
   "source": [
    "1.   Well-structured, formatted, and commented code is required.\n",
    "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
    "     \n",
    "     The additional credits will have advantages over other students during Star Student selection.\n",
    "       \n",
    "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
    "                       without a single error logged. ]\n",
    "\n",
    "3.   Each and every logic should have proper comments.\n",
    "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
    "        \n",
    "\n",
    "```\n",
    "# Chart visualization code\n",
    "```\n",
    "            \n",
    "\n",
    "*   Why did you pick the specific chart?\n",
    "*   What is/are the insight(s) found from the chart?\n",
    "* Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason.\n",
    "\n",
    "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
    "\n",
    "\n",
    "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
    "\n",
    "U - Univariate Analysis,\n",
    "\n",
    "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
    "\n",
    "M - Multivariate Analysis\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
    "\n",
    "\n",
    "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
    "\n",
    "\n",
    "*   Cross- Validation & Hyperparameter Tuning\n",
    "\n",
    "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
    "\n",
    "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_i_v8NEhb9l"
   },
   "source": [
    "# ***Let's Begin !***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhfV-JJviCcP"
   },
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3lxredqlCYt"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8Vqi-pPk-HR"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import pickle\n",
    "import zipfile\n",
    "import gdown\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RnN4peoiCZX"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "output_path = \"data.zip\"\n",
    "\n",
    "# Create dataset directory in current folder\n",
    "\n",
    "extract_dir = \"data\"\n",
    "\n",
    "# Download dataset\n",
    "\n",
    "gdown.download(f\"https://drive.google.com/uc?id={FILE_ID}\", output_path, quiet=False)\n",
    "print(\"\\n Downloaded Zip File from GDrive\")\n",
    "\n",
    "# Extract dataset\n",
    "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(\"\\n Extracted zip into 'data' \")\n",
    "\n",
    "# Clean up\n",
    "os.remove(output_path)\n",
    "\n",
    "# Update base path\n",
    "DATASET_BASE = os.path.join(extract_dir, \"data\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATASET_BASE, 'train')\n",
    "VAL_PATH = os.path.join(DATASET_BASE, 'val')\n",
    "TEST_PATH = os.path.join(DATASET_BASE, 'test')\n",
    "\n",
    "print(f\"Train Path : {TRAIN_PATH}\")\n",
    "print(f\"Valid Path : {VAL_PATH}\")\n",
    "print(f\"Test Path : {TEST_PATH}\")\n",
    "\n",
    "print(\"\\n Dataset Folders Created Succesfully !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "outputs": [],
   "source": [
    "# Dataset First Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "outputs": [],
   "source": [
    "# Dataset Rows & Columns count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9hRXRi6meOf"
   },
   "outputs": [],
   "source": [
    "# Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35m5QtbWiB9F"
   },
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "outputs": [],
   "source": [
    "# Dataset Duplicate Value Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPl-ycgm1ru"
   },
   "source": [
    "#### Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "outputs": [],
   "source": [
    "# Missing Values/Null Values Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q5wnI3om9sJ"
   },
   "outputs": [],
   "source": [
    "# Visualizing the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0kj-8xxnORC"
   },
   "source": [
    "### What did you know about your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfoNAAC-nUe_"
   },
   "source": [
    "The given dataset contained folders train,test and val. Each of the folders had images of fishes of 11 categories which where:\n",
    "\n",
    "1. Animal Fish (animal fish)\n",
    "2. Animal Fish Bass (animal fish bass)\n",
    "3. Fish Sea Food Black Sea Sprat (fish sea_food black_sea_sprat)\n",
    "4. Fish Sea Food Gilt Head Bream (fish sea_food gilt_head_bream)\n",
    "5. Fish Sea Food Hourse Mackerel (fish sea_food hourse_mackerel)\n",
    "6. Fish Sea Food Red Mullet (fish sea_food red_mullet)\n",
    "7. Fish Sea Food Red Sea Bream (fish sea_food red_sea_bream)\n",
    "8. Fish Sea Food Sea Bass (fish sea_food sea_bass)\n",
    "9. Fish Sea Food Shrimp (fish sea_food shrimp)\n",
    "10. Fish Sea Food Striped Red Mullet (fish sea_food striped_red_mullet)\n",
    "11. Fish Sea Food Trout (fish sea_food trout)\n",
    "\n",
    "The data was extracted in such a way because the dataset has a size of 240+ MB hence it had to be uploaded to drive and from there it is extracted to a folder data from which the images are accessed. By this method, anyone can access the files by running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7xfkqrt5Ag5"
   },
   "outputs": [],
   "source": [
    "# Dataset Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnOaZdaE5Q5t"
   },
   "outputs": [],
   "source": [
    "# Dataset Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBTbrJXOngz2"
   },
   "source": [
    "### Variables Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJV4KIxSnxay"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3PMJOP6ngxN"
   },
   "source": [
    "### Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zms12Yq5n-jE"
   },
   "outputs": [],
   "source": [
    "# Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKJF3rekwFvQ"
   },
   "source": [
    "### Data Wrangling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk-9a2fpoLcV"
   },
   "outputs": [],
   "source": [
    "# Write your code to make your dataset analysis ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSa1f5Uengrz"
   },
   "source": [
    "### What all manipulations have you done and insights you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbyXE7I1olp8"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wOQAZs5pc--"
   },
   "source": [
    "#### Chart - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "outputs": [],
   "source": [
    "# Chart - 1 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5QZ13OEpz2H"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XESiWehPqBRc"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ7QKXXCp7Bj"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_j1G7yiqdRP"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "448CDAPjqfQr"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cspy4FjqxJW"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSlN3yHqYklG"
   },
   "source": [
    "#### Chart - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4YgtaqtYklH"
   },
   "outputs": [],
   "source": [
    "# Chart - 2 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6dVpIINYklI"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aaW0BYyYklI"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijmpgYnKYklI"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSx9atu2YklI"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JiQyfWJYklI"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcBbebzrYklV"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM7whBJCYoAo"
   },
   "source": [
    "#### Chart - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6GMdE67YoAp"
   },
   "outputs": [],
   "source": [
    "# Chart - 3 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fge-S5ZAYoAp"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dBItgRVYoAp"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85gYPyotYoAp"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jstXR6OYoAp"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoGjAbkUYoAp"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfJ8IqMcYoAp"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Of9eVA-YrdM"
   },
   "source": [
    "#### Chart - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irlUoxc8YrdO"
   },
   "outputs": [],
   "source": [
    "# Chart - 4 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iky9q4vBYrdO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJRCwT6DYrdO"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6T5p64dYrdO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx8WAJvtYrdO"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Ehk30pYrdP"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLNxxz7MYrdP"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bamQiAODYuh1"
   },
   "source": [
    "#### Chart - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIJwrbroYuh3"
   },
   "outputs": [],
   "source": [
    "# Chart - 5 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHF8YVU7Yuh3"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcxuIMRPYuh3"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwzvFGzlYuh3"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyqkiB8YYuh3"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYpmQ266Yuh3"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WtzZ_hCYuh4"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH-pJp9IphqM"
   },
   "source": [
    "#### Chart - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuRf4wtuphqN"
   },
   "outputs": [],
   "source": [
    "# Chart - 6 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbFf2-_FphqN"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loh7H2nzphqN"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ouA3fa0phqN"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VECbqPI7phqN"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Seke61FWphqN"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW4_bGpfphqN"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIIx-8_IphqN"
   },
   "source": [
    "#### Chart - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqAIGUfyphqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 7 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t27r6nlMphqO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iv6ro40sphqO"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2jJGEOYphqO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po6ZPi4hphqO"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0JNsNcRphqO"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvSq8iUTphqO"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZR9WyysphqO"
   },
   "source": [
    "#### Chart - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdPTWpAVphqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 8 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj7wYXLtphqO"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob8u6rCTphqO"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZrbJ2SmphqO"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZtgC_hjphqO"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFu4xreNphqO"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey_0qi68phqO"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ55k-q6phqO"
   },
   "source": [
    "#### Chart - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2aS4O1ophqO"
   },
   "outputs": [],
   "source": [
    "# Chart - 9 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCFgpxoyphqP"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVxDimi2phqP"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVtJsKN_phqQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngGi97qjphqQ"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lssrdh5qphqQ"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBpY5ekJphqQ"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2RJ9gkRphqQ"
   },
   "source": [
    "#### Chart - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM7a4YP4phqQ"
   },
   "outputs": [],
   "source": [
    "# Chart - 10 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M8mcRywphqQ"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8agQvks0phqQ"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgIPom80phqQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp13pnNzphqQ"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMzcOPDDphqR"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Ka1PC2phqR"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-EpHcCOp1ci"
   },
   "source": [
    "#### Chart - 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAQTIvtqp1cj"
   },
   "outputs": [],
   "source": [
    "# Chart - 11 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_VqEhTip1ck"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vsMzt_np1ck"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zGJKyg5p1ck"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYdMsrqVp1ck"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVzmfK_Ep1ck"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "druuKYZpp1ck"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3dbpmDWp1ck"
   },
   "source": [
    "#### Chart - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwevp1tKp1ck"
   },
   "outputs": [],
   "source": [
    "# Chart - 12 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylSl6qgtp1ck"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2xqNkiQp1ck"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWILFDl5p1ck"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-lUsV2mp1ck"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7G43BXep1ck"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wwDJXsLp1cl"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag9LCva-p1cl"
   },
   "source": [
    "#### Chart - 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUfxeq9-p1cl"
   },
   "outputs": [],
   "source": [
    "# Chart - 13 visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6MkPsBcp1cl"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V22bRsFWp1cl"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cELzS2fp1cl"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozQPc2_Ip1cl"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MPXvC8up1cl"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GL8l1tdLp1cl"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC_X3p0fY2L0"
   },
   "source": [
    "#### Chart - 14 - Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyC9zolEZNRQ"
   },
   "outputs": [],
   "source": [
    "# Correlation Heatmap visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV0SzAkaZNRQ"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVPuT8LYZNRQ"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEH6qLeZNRQ"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfSqtnDqZNRR"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q29F0dvdveiT"
   },
   "source": [
    "#### Chart - 15 - Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o58-TEIhveiU"
   },
   "outputs": [],
   "source": [
    "# Pair Plot visualization code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXh0U9oCveiU"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMmPjTByveiU"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22aHeOlLveiV"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPQ8RGwHveiV"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfr_Vlr8HBkt"
   },
   "source": [
    "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7MS06SUHkB-"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yEUt7NnHlrM"
   },
   "source": [
    "### Hypothetical Statement - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEA2Xm5dHt1r"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI9ZP0laH0D-"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I79__PHVH19G"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZrfquKtyian"
   },
   "outputs": [],
   "source": [
    "# Perform Statistical Test to obtain P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou-I18pAyIpj"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2U0kk00ygSB"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF3858GYyt-u"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO4K0gP5y3B4"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_0_7-oCpUZd"
   },
   "source": [
    "### Hypothetical Statement - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwyV_J3ipUZe"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnpLGJ-4pUZe"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yB-zSqbpUZe"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWxdNTXNpUZe"
   },
   "outputs": [],
   "source": [
    "# Perform Statistical Test to obtain P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEUvejAfpUZe"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLDrPz7HpUZf"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd15vwWVpUZf"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xOGYyiBpUZf"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn_IUdTipZyH"
   },
   "source": [
    "### Hypothetical Statement - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49K5P_iCpZyH"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gWI5rT9pZyH"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nff-vKELpZyI"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6AnJQjtpZyI"
   },
   "outputs": [],
   "source": [
    "# Perform Statistical Test to obtain P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLW572S8pZyI"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytWJ8v15pZyI"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbDXHzopZyI"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M99G98V6pZyI"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjJCtPM0KBk"
   },
   "source": [
    "## ***2. Data Augmentation & Engineering***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjJCtPM0KBk"
   },
   "source": [
    "### Generating Image Data for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Create directories for saving models\n",
    "os.makedirs('/data/models', exist_ok=True)\n",
    "\n",
    "print(\"\\n Generating Data for Models to be trained on\")\n",
    "\n",
    "# Data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class information\n",
    "NUM_CLASSES = len(train_generator.class_indices)\n",
    "CLASS_NAMES = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Clean up class names for better display\n",
    "CLEAN_CLASS_NAMES = []\n",
    "for name in CLASS_NAMES:\n",
    "    clean_name = name.replace('animal_fish_', '').replace('fish_sea_food_', '').replace('_', ' ').title()\n",
    "    CLEAN_CLASS_NAMES.append(clean_name)\n",
    "\n",
    "print(f\"\\n📊 Dataset Info:\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "\n",
    "print(f\"\\n🏷️ Fish Classes:\")\n",
    "for i, (orig, clean) in enumerate(zip(CLASS_NAMES, CLEAN_CLASS_NAMES), 1):\n",
    "    print(f\"{i:2d}. {clean} ({orig})\")\n",
    "\n",
    "# Save class names\n",
    "with open('/data/models/class_names.pkl', 'wb') as f:\n",
    "    pickle.dump(CLEAN_CLASS_NAMES, f)\n",
    "\n",
    "with open('/data/models/original_class_names.pkl', 'wb') as f:\n",
    "    pickle.dump(CLASS_NAMES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ixusLtI0pqI"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6w2CzZf04JK"
   },
   "outputs": [],
   "source": [
    "# Handling Outliers & Outlier treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "578E2V7j08f6"
   },
   "source": [
    "##### What all outlier treatment techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGZz5OrT1HH-"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21JmIYMG2hEo"
   },
   "outputs": [],
   "source": [
    "# Encode your categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDaue5h32n_G"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTouz10C3oNN"
   },
   "outputs": [],
   "source": [
    "# Expand Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88JnJ1jN3w7j"
   },
   "outputs": [],
   "source": [
    "# Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqbBqNaA33c0"
   },
   "outputs": [],
   "source": [
    "# Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sxKgKxu4Ip3"
   },
   "outputs": [],
   "source": [
    "# Remove URLs & Remove words and digits contain digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2LSJh154s8W"
   },
   "outputs": [],
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgLJGffy4vm0"
   },
   "outputs": [],
   "source": [
    "# Remove White spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foqY80Qu48N2"
   },
   "outputs": [],
   "source": [
    "# Rephrase Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijx1rUOS5CUU"
   },
   "outputs": [],
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIJ1a-Zc5PY8"
   },
   "outputs": [],
   "source": [
    "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJNqERVU536h"
   },
   "source": [
    "##### Which text normalization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9jKVxE06BC1"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btT3ZJBAO6Ik"
   },
   "outputs": [],
   "source": [
    "# POS Taging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBRtdhth6JDE"
   },
   "outputs": [],
   "source": [
    "# Vectorizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBMux9mC6MCf"
   },
   "source": [
    "##### Which text vectorization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su2EnbCh6UKQ"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1qC4yhBApWC"
   },
   "outputs": [],
   "source": [
    "# Manipulate Features to minimize feature correlation and create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLhe8UmaBCEE"
   },
   "outputs": [],
   "source": [
    "# Select your features wisely to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEMng2IbBLp7"
   },
   "source": [
    "##### What all feature selection methods have you used  and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb2Lh6Z8BgGs"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAdphbQ9Bhjc"
   },
   "source": [
    "##### Which all features you found important and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGgaEstsBnaf"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6quWQ1T9rtH"
   },
   "outputs": [],
   "source": [
    "# Transform Your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL9LWpySC6x_"
   },
   "outputs": [],
   "source": [
    "# Scaling your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiiVWRdJDDil"
   },
   "source": [
    "##### Which method have you used to scale you data and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kexQrXU-DjzY"
   },
   "source": [
    "##### Do you think that dimensionality reduction is needed? Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGRlBsSGDtTQ"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQfvxBBHDvCa"
   },
   "outputs": [],
   "source": [
    "# DImensionality Reduction (If needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5CmagL3EC8N"
   },
   "source": [
    "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKr75IDuEM7t"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CTyd2UwEyNM"
   },
   "outputs": [],
   "source": [
    "# Split your data to train and test. Choose Splitting ratio wisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKvONjwE8ra"
   },
   "source": [
    "##### What data splitting ratio have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2lJ8cobFDb_"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOzZv6IFROw"
   },
   "source": [
    "##### Do you think the dataset is imbalanced? Explain Why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeKDIv7pFgcC"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQsRhhZLFiDs"
   },
   "outputs": [],
   "source": [
    "# Handling Imbalanced Dataset (If needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIqpNgepFxVj"
   },
   "source": [
    "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbet1HwdGDTz"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfCC591jGiD4"
   },
   "source": [
    "## ***3. ML Model Implementation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB4l2ZhMeS1U"
   },
   "source": [
    "### Creating CNN, Usage and Training of other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ebyywQieS1U"
   },
   "outputs": [],
   "source": [
    "#Creating Models\n",
    "\n",
    "print(\"\\n Creating and Training and Evaluating Models\")\n",
    "\n",
    "#1. CNN MODEL\n",
    "\n",
    "def create_cnn_from_scratch():\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_transfer_learning_model(base_model_name, input_shape=(224, 224, 3)):\n",
    "    base_models = {\n",
    "        'VGG16': VGG16,\n",
    "        'ResNet50': ResNet50,\n",
    "        'MobileNetV2': MobileNetV2,\n",
    "        'EfficientNetB0': EfficientNetB0\n",
    "    }\n",
    "    \n",
    "    base_model = base_models[base_model_name](\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Training Models \n",
    "\n",
    "def train_model(model, model_name, epochs=EPOCHS):\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "        ModelCheckpoint(\n",
    "            f'/data/models/{model_name}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n🚀 Training {model_name}...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "#Compare Models\n",
    "\n",
    "def evaluate_model(model, model_name, history):\n",
    "    \n",
    "    # Evaluate on validation and test data\n",
    "    val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
    "    \n",
    "    # Get predictions on test data\n",
    "    test_generator.reset()\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(\n",
    "        true_classes, \n",
    "        predicted_classes, \n",
    "        target_names=CLEAN_CLASS_NAMES,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_loss': val_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_loss': test_loss,\n",
    "        'classification_report': report,\n",
    "        'history': history.history\n",
    "    }\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    ax1.set_title(f'{model_name} - Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    ax2.set_title(f'{model_name} - Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/data/models/{model_name}_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#MODEL TRAINING LOOP\n",
    "print(\"\\n🚀 Starting Model Training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Models to train\n",
    "models_to_train = [\n",
    "    ('CNN', create_cnn_from_scratch),\n",
    "    ('VGG16', lambda: create_transfer_learning_model('VGG16')),\n",
    "    ('ResNet50', lambda: create_transfer_learning_model('ResNet50')),\n",
    "    ('MobileNetV2', lambda: create_transfer_learning_model('MobileNetV2')),\n",
    "    ('EfficientNetB0', lambda: create_transfer_learning_model('EfficientNetB0'))\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "# Train all models\n",
    "for model_name, model_func in models_to_train:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🧠 TRAINING: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = model_func()\n",
    "    print(f\"📊 Model Parameters: {model.count_params():,}\")\n",
    "    \n",
    "    # Train model\n",
    "    history = train_model(model, model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    result = evaluate_model(model, model_name, history)\n",
    "    results.append(result)\n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history, model_name)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n📈 {model_name} Results:\")\n",
    "    print(f\"   Validation Accuracy: {result['val_accuracy']:.4f}\")\n",
    "    print(f\"   Test Accuracy: {result['test_accuracy']:.4f}\")\n",
    "    print(f\"   Test Loss: {result['test_loss']:.4f}\")\n",
    "\n",
    "#Comparison\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for result in results:\n",
    "    comparison_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Validation Accuracy': result['val_accuracy'],\n",
    "        'Test Accuracy': result['test_accuracy'],\n",
    "        'Validation Loss': result['val_loss'],\n",
    "        'Test Loss': result['test_loss'],\n",
    "        'Precision (Macro)': result['classification_report']['macro avg']['precision'],\n",
    "        'Recall (Macro)': result['classification_report']['macro avg']['recall'],\n",
    "        'F1-Score (Macro)': result['classification_report']['macro avg']['f1-score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🏆 FINAL MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.round(4).to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "best_test_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "best_val_accuracy = comparison_df.iloc[0]['Validation Accuracy']\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"🎯 Test Accuracy: {best_test_accuracy:.4f}\")\n",
    "print(f\"📊 Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('/data/models/best_model.h5')\n",
    "print(f\"\\n✅ Best model saved as '/data/models/best_model.h5'\")\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('/data/models/model_comparison.csv', index=False)\n",
    "\n",
    "# Save detailed results\n",
    "with open('/data/models/detailed_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# Model comparison plots\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Validation Accuracy\n",
    "plt.subplot(2, 3, 1)\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['Validation Accuracy'], color='lightblue', alpha=0.8)\n",
    "plt.title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{comparison_df.iloc[i][\"Validation Accuracy\"]:.3f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Test Accuracy\n",
    "plt.subplot(2, 3, 2)\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['Test Accuracy'], color='lightgreen', alpha=0.8)\n",
    "plt.title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, \n",
    "             f'{comparison_df.iloc[i][\"Test Accuracy\"]:.3f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Validation Loss\n",
    "plt.subplot(2, 3, 3)\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['Validation Loss'], color='lightcoral', alpha=0.8)\n",
    "plt.title('Validation Loss Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# F1-Score\n",
    "plt.subplot(2, 3, 4)\n",
    "bars = plt.bar(comparison_df['Model'], comparison_df['F1-Score (Macro)'], color='lightyellow', alpha=0.8)\n",
    "plt.title('F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Combined metrics\n",
    "plt.subplot(2, 3, 5)\n",
    "metrics = ['Precision (Macro)', 'Recall (Macro)', 'F1-Score (Macro)']\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, comparison_df[metric], width, label=metric.split(' ')[0], alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall, F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x + width, comparison_df['Model'], rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy comparison (Val vs Test)\n",
    "plt.subplot(2, 3, 6)\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, comparison_df['Validation Accuracy'], width, label='Validation', alpha=0.8, color='blue')\n",
    "plt.bar(x + width/2, comparison_df['Test Accuracy'], width, label='Test', alpha=0.8, color='orange')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation vs Test Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, comparison_df['Model'], rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/data/models/model_comparison_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Generate confusion matrix for best model\n",
    "\n",
    "test_generator.reset()\n",
    "predictions = best_model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLEAN_CLASS_NAMES, yticklabels=CLEAN_CLASS_NAMES,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/data/models/confusion_matrix_best_model.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Downloading Results\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"🏆 Best Model: {best_model_name}\")\n",
    "print(f\"🎯 Test Accuracy: {best_test_accuracy:.4f}\")\n",
    "print(f\"📊 Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n📁 Files saved in '/data/models/':\")\n",
    "print(\"   ✅ best_model.h5 (best performing model)\")\n",
    "print(\"   ✅ class_names.pkl (clean class names)\")\n",
    "print(\"   ✅ original_class_names.pkl (original folder names)\")\n",
    "print(\"   ✅ model_comparison.csv (comparison results)\")\n",
    "print(\"   ✅ detailed_results.pkl (detailed results)\")\n",
    "print(\"   ✅ Training history plots\")\n",
    "print(\"   ✅ Model comparison plots\")\n",
    "print(\"   ✅ Confusion matrix\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(\"1. Download 'best_model.h5' and 'class_names.pkl'\")\n",
    "print(\"2. Use these files in your Streamlit app\")\n",
    "print(\"3. Deploy your fish classification app!\")\n",
    "\n",
    "# Zip all results for easy download\n",
    "print(f\"\\n📦 Creating download package...\")\n",
    "import shutil\n",
    "shutil.make_archive('/data/fish_classification_results', 'zip', '/data/models')\n",
    "print(\"✅ Results packaged in: /data/fish_classification_results.zip\")\n",
    "\n",
    "# Show final class mapping\n",
    "print(f\"\\n🏷️ FINAL CLASS MAPPING:\")\n",
    "for i, (orig, clean) in enumerate(zip(CLASS_NAMES, CLEAN_CLASS_NAMES)):\n",
    "    print(f\"{i+1:2d}. '{orig}' → '{clean}'\")\n",
    "\n",
    "\n",
    "print(f\"\\n🎊 Fish Classification Project Complete! 🐟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiV4Ypx8fxKe"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "negyGRa7fxKf"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfvqoZmBfxKf"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLui8CcfxKf"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWYfwnehpsJ1"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEl-hgQWpsJ1"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jK_YjpMpsJ2"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn0EOfS6psJ2"
   },
   "outputs": [],
   "source": [
    "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAih1iBOpsJ2"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kBgjYcdpsJ2"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVGeBEFhpsJ2"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74yRdG6UpsJ3"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmKjuQ-FpsJ3"
   },
   "source": [
    "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDKtOrBQpsJ3"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFrSXAtrpx6M"
   },
   "outputs": [],
   "source": [
    "# ML Model - 3 Implementation\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AN1z2sKpx6M"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIY4lxxGpx6M"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PIHJqyupx6M"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSVXuaSKpx6M"
   },
   "outputs": [],
   "source": [
    "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-qAgymDpx6N"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQMffxkwpx6N"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-hykwinpx6N"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzVzZC6opx6N"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHVz9hHDKFms"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBFFvTBNJzUa"
   },
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ksF5Q1LKTVm"
   },
   "source": [
    "I have chosen MobileNetV2 as its the best perfoming out of all the ones used. The training was done in just 10 epochs due to many constraints but still MobileNetV2 was able to achieve highest levels of accuracy combined with lowest levels of loss out of all models. The main reason behind this might be due to the Mobility of this model to process all the data on such short epoch range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvVTiIxBL-C"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***8.*** ***Future Work***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW_Lq9qf2h6X"
   },
   "source": [
    "### 1. Streamlit App Deployment Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW_Lq9qf2h6X"
   },
   "source": [
    "App Link - https://fish-image-classification.streamlit.app/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEXk9ydD2nVC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "model_json_path = Path(\"data/models/mobilenetv2_model.json\")\n",
    "model_weights_path = Path(\"data/models/mobilenetv2.weights.h5\")\n",
    "class_names_path = Path(\"data/models/class_names.pkl\")\n",
    "\n",
    "if not model_json_path.exists() or not model_weights_path.exists() or not class_names_path.exists():\n",
    "    raise FileNotFoundError(\"Model JSON, weights file, or class names file not found in data/models/ folder.\")\n",
    "\n",
    "with open(model_json_path, \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "model.load_weights(model_weights_path)\n",
    "\n",
    "with open(class_names_path, \"rb\") as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "st.set_page_config(page_title=\"Fish Species Classifier\", layout=\"centered\")\n",
    "\n",
    "st.markdown(\"<h1 style='text-align: center; color: #1f77b4;'>🐟 Fish Species Classification</h1>\", unsafe_allow_html=True)\n",
    "st.markdown(\"<p style='text-align: center; font-size:18px;'>Upload an image of a fish to identify its species.</p>\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 🐠 Current Supported Fish Types:\n",
    "\n",
    "1. **Animal Fish** (`animal fish`)  \n",
    "2. **Animal Fish Bass** (`animal fish bass`)  \n",
    "3. **Fish Sea Food Black Sea Sprat** (`fish sea_food black_sea_sprat`)  \n",
    "4. **Fish Sea Food Gilt Head Bream** (`fish sea_food gilt_head_bream`)  \n",
    "5. **Fish Sea Food Hourse Mackerel** (`fish sea_food hourse_mackerel`)  \n",
    "6. **Fish Sea Food Red Mullet** (`fish sea_food red_mullet`)  \n",
    "7. **Fish Sea Food Red Sea Bream** (`fish sea_food red_sea_bream`)  \n",
    "8. **Fish Sea Food Sea Bass** (`fish sea_food sea_bass`)  \n",
    "9. **Fish Sea Food Shrimp** (`fish sea_food shrimp`)  \n",
    "10. **Fish Sea Food Striped Red Mullet** (`fish sea_food striped_red_mullet`)  \n",
    "11. **Fish Sea Food Trout** (`fish sea_food trout`)\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"### 📂 Upload Your Image\")\n",
    "uploaded_file = st.file_uploader(\"\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "st.markdown(\"### 📸 Or Try a Sample Image\")\n",
    "SAMPLES_FOLDER = Path(\"samples\")\n",
    "sample_images = {\n",
    "    \"Head Bream Fish\": SAMPLES_FOLDER / \"hb.jpg\",\n",
    "    \"Horse Mackarel Fish\": SAMPLES_FOLDER / \"hm.jpg\",\n",
    "    \"Sea Sprat Fish\": SAMPLES_FOLDER / \"ss.jpg\",\n",
    "    \"Striped Red Mullet\": SAMPLES_FOLDER / \"srm.jpg\"\n",
    "}\n",
    "\n",
    "sample_choice = st.selectbox(\"Or pick a sample image:\", list(sample_images.keys()))\n",
    "if st.button(\"Use Sample Image\"):\n",
    "    uploaded_file = open(sample_images[sample_choice], \"rb\")\n",
    "\n",
    "if uploaded_file:\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    img_resized = image.resize((224, 224))\n",
    "    img_array = np.array(img_resized) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # shape (1, 224, 224, 3)\n",
    "\n",
    "    predictions = model.predict(img_array)[0]\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    top_indices = predictions.argsort()[-4:][::-1]  # top 4\n",
    "\n",
    "    st.markdown(\"## 🏆 Prediction Result\")\n",
    "    st.markdown(\n",
    "        f\"<h3 style='color: green;'>✅ {class_names[top_indices[0]]} ({predictions[top_indices[0]]*100:.2f}%)</h3>\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "    st.markdown(\"### 🔍 Other Possible Species\")\n",
    "    for idx in top_indices[1:]:\n",
    "        st.markdown(f\"- **{class_names[idx]}** ({predictions[idx]*100:.2f}%)\")\n",
    "\n",
    "st.markdown(\"<p style='text-align: center; font-size:14px;'>A Project made by Aswin K J</p>\", unsafe_allow_html=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Kee-DAl2viO"
   },
   "source": [
    "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCX9965dhzqZ"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjb1IsQkh3yE"
   },
   "source": [
    "Based on the comprehensive analysis documented in the notebook, the project successfully identified the optimal deep learning architecture for classifying the given dataset of 11 fish species. Through a comparative study of five different models, the **MobileNetV2** architecture demonstrated overwhelmingly superior performance, achieving a near-perfect **test accuracy of 99.34%**. The success of this model can be attributed to the effective use of transfer learning combined with data augmentation techniques, which prevented overfitting and allowed the model to generalize well. The project concludes with a production-ready model saved as `best_model.h5` along with a `class_names.pkl` containing all the class names. A seperate `mobilenetv2.weights.h5` weights file had to be created due to model loading constraints and the model was loaded live in the app.py and the app was successfully deployed in the Streamlit Cloud and the project was successfully completed !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIfDvo9L0UH2"
   },
   "source": [
    "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vncDsAP0Gaoa",
    "FJNUwmbgGyua",
    "w6K7xa23Elo4",
    "yQaldy8SH6Dl",
    "mDgbUHAGgjLW",
    "O_i_v8NEhb9l",
    "HhfV-JJviCcP",
    "Y3lxredqlCYt",
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "nA9Y7ga8ng1Z",
    "PBTbrJXOngz2",
    "u3PMJOP6ngxN",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "K5QZ13OEpz2H",
    "lQ7QKXXCp7Bj",
    "448CDAPjqfQr",
    "KSlN3yHqYklG",
    "t6dVpIINYklI",
    "ijmpgYnKYklI",
    "-JiQyfWJYklI",
    "EM7whBJCYoAo",
    "fge-S5ZAYoAp",
    "85gYPyotYoAp",
    "RoGjAbkUYoAp",
    "4Of9eVA-YrdM",
    "iky9q4vBYrdO",
    "F6T5p64dYrdO",
    "y-Ehk30pYrdP",
    "bamQiAODYuh1",
    "QHF8YVU7Yuh3",
    "GwzvFGzlYuh3",
    "qYpmQ266Yuh3",
    "OH-pJp9IphqM",
    "bbFf2-_FphqN",
    "_ouA3fa0phqN",
    "Seke61FWphqN",
    "PIIx-8_IphqN",
    "t27r6nlMphqO",
    "r2jJGEOYphqO",
    "b0JNsNcRphqO",
    "BZR9WyysphqO",
    "jj7wYXLtphqO",
    "eZrbJ2SmphqO",
    "rFu4xreNphqO",
    "YJ55k-q6phqO",
    "gCFgpxoyphqP",
    "OVtJsKN_phqQ",
    "lssrdh5qphqQ",
    "U2RJ9gkRphqQ",
    "1M8mcRywphqQ",
    "tgIPom80phqQ",
    "JMzcOPDDphqR",
    "x-EpHcCOp1ci",
    "X_VqEhTip1ck",
    "8zGJKyg5p1ck",
    "PVzmfK_Ep1ck",
    "n3dbpmDWp1ck",
    "ylSl6qgtp1ck",
    "ZWILFDl5p1ck",
    "M7G43BXep1ck",
    "Ag9LCva-p1cl",
    "E6MkPsBcp1cl",
    "2cELzS2fp1cl",
    "3MPXvC8up1cl",
    "NC_X3p0fY2L0",
    "UV0SzAkaZNRQ",
    "YPEH6qLeZNRQ",
    "q29F0dvdveiT",
    "EXh0U9oCveiU",
    "22aHeOlLveiV",
    "g-ATYxFrGrvw",
    "Yfr_Vlr8HBkt",
    "8yEUt7NnHlrM",
    "tEA2Xm5dHt1r",
    "I79__PHVH19G",
    "Ou-I18pAyIpj",
    "fF3858GYyt-u",
    "4_0_7-oCpUZd",
    "hwyV_J3ipUZe",
    "3yB-zSqbpUZe",
    "dEUvejAfpUZe",
    "Fd15vwWVpUZf",
    "bn_IUdTipZyH",
    "49K5P_iCpZyH",
    "Nff-vKELpZyI",
    "kLW572S8pZyI",
    "dWbDXHzopZyI",
    "yLjJCtPM0KBk",
    "xiyOF9F70UgQ",
    "7wuGOrhz0itI",
    "id1riN9m0vUs",
    "578E2V7j08f6",
    "89xtkJwZ18nB",
    "67NQN5KX2AMe",
    "Iwf50b-R2tYG",
    "GMQiZwjn3iu7",
    "WVIkgGqN3qsr",
    "XkPnILGE3zoT",
    "Hlsf0x5436Go",
    "mT9DMSJo4nBL",
    "c49ITxTc407N",
    "OeJFEK0N496M",
    "9ExmJH0g5HBk",
    "cJNqERVU536h",
    "k5UmGsbsOxih",
    "T0VqWOYE6DLQ",
    "qBMux9mC6MCf",
    "-oLEiFgy-5Pf",
    "C74aWNz2AliB",
    "2DejudWSA-a0",
    "pEMng2IbBLp7",
    "rAdphbQ9Bhjc",
    "TNVZ9zx19K6k",
    "nqoHp30x9hH9",
    "rMDnDkt2B6du",
    "yiiVWRdJDDil",
    "1UUpS68QDMuG",
    "kexQrXU-DjzY",
    "T5CmagL3EC8N",
    "BhH2vgX9EjGr",
    "qjKvONjwE8ra",
    "P1XJ9OREExlT",
    "VFOzZv6IFROw",
    "TIqpNgepFxVj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "4qY1EAkEfxKe",
    "PiV4Ypx8fxKe",
    "TfvqoZmBfxKf",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "-jK_YjpMpsJ2",
    "HAih1iBOpsJ2",
    "zVGeBEFhpsJ2",
    "bmKjuQ-FpsJ3",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "9PIHJqyupx6M",
    "_-qAgymDpx6N",
    "Z-hykwinpx6N",
    "h_CCil-SKHpo",
    "cBFFvTBNJzUa",
    "HvGl1hHyA_VK",
    "EyNgTHvd2WFk",
    "KH5McJBi2d8v",
    "iW_Lq9qf2h6X",
    "-Kee-DAl2viO",
    "gCX9965dhzqZ",
    "gIfDvo9L0UH2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
